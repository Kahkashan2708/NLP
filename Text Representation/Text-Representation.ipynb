{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Bag of Words","metadata":{}},{"cell_type":"code","source":"import nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:44:28.858574Z","iopub.execute_input":"2025-09-29T09:44:28.858858Z","iopub.status.idle":"2025-09-29T09:44:29.950077Z","shell.execute_reply.started":"2025-09-29T09:44:28.858838Z","shell.execute_reply":"2025-09-29T09:44:29.949095Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:33:23.007755Z","iopub.execute_input":"2025-09-29T09:33:23.008089Z","iopub.status.idle":"2025-09-29T09:33:23.013299Z","shell.execute_reply.started":"2025-09-29T09:33:23.008064Z","shell.execute_reply":"2025-09-29T09:33:23.012067Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"text = \"\"\"Natural Language Processing is a subfield of Artificial Intelligence.\nMachine learning techniques are widely used in NLP tasks such as text classification.\nDeep learning models like RNNs and Transformers have improved NLP performance.\nBag of Words is one of the simplest text vectorization techniques.\nTF-IDF and word embeddings are more advanced alternatives to Bag of Words.\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:43:34.268642Z","iopub.execute_input":"2025-09-29T09:43:34.269984Z","iopub.status.idle":"2025-09-29T09:43:34.274750Z","shell.execute_reply.started":"2025-09-29T09:43:34.269938Z","shell.execute_reply":"2025-09-29T09:43:34.273765Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Download the tokenizer\nnltk.download('punkt')\ncorpus = nltk.sent_tokenize(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:45:39.362487Z","iopub.execute_input":"2025-09-29T09:45:39.362790Z","iopub.status.idle":"2025-09-29T09:45:39.368217Z","shell.execute_reply.started":"2025-09-29T09:45:39.362768Z","shell.execute_reply":"2025-09-29T09:45:39.367229Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### The Punkt tokenizer is a pre-trained, unsupervised sentence tokenizer that comes with NLTK. It breaks text into sentences.","metadata":{}},{"cell_type":"code","source":"# Sentence splitting\ncorpus = nltk.sent_tokenize(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:46:06.992792Z","iopub.execute_input":"2025-09-29T09:46:06.993706Z","iopub.status.idle":"2025-09-29T09:46:06.998686Z","shell.execute_reply.started":"2025-09-29T09:46:06.993677Z","shell.execute_reply":"2025-09-29T09:46:06.997564Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"print(\"Documents (after splitting):\")\nfor i, doc in enumerate(corpus, 1):\n    print(f\"{i}: {doc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:46:14.214310Z","iopub.execute_input":"2025-09-29T09:46:14.214596Z","iopub.status.idle":"2025-09-29T09:46:14.220033Z","shell.execute_reply.started":"2025-09-29T09:46:14.214568Z","shell.execute_reply":"2025-09-29T09:46:14.219197Z"}},"outputs":[{"name":"stdout","text":"Documents (after splitting):\n1: Natural Language Processing is a subfield of Artificial Intelligence.\n2: Machine learning techniques are widely used in NLP tasks such as text classification.\n3: Deep learning models like RNNs and Transformers have improved NLP performance.\n4: Bag of Words is one of the simplest text vectorization techniques.\n5: TF-IDF and word embeddings are more advanced alternatives to Bag of Words.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Bag of words\nvectorizer = CountVectorizer()\nbow = vectorizer.fit_transform(corpus)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:47:19.922964Z","iopub.execute_input":"2025-09-29T09:47:19.923418Z","iopub.status.idle":"2025-09-29T09:47:19.928939Z","shell.execute_reply.started":"2025-09-29T09:47:19.923385Z","shell.execute_reply":"2025-09-29T09:47:19.928187Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"print(\" Vocabulary:\", vectorizer.get_feature_names_out())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:47:40.773314Z","iopub.execute_input":"2025-09-29T09:47:40.773607Z","iopub.status.idle":"2025-09-29T09:47:40.780268Z","shell.execute_reply.started":"2025-09-29T09:47:40.773586Z","shell.execute_reply":"2025-09-29T09:47:40.778930Z"}},"outputs":[{"name":"stdout","text":" Vocabulary: ['advanced' 'alternatives' 'and' 'are' 'artificial' 'as' 'bag'\n 'classification' 'deep' 'embeddings' 'have' 'idf' 'improved' 'in'\n 'intelligence' 'is' 'language' 'learning' 'like' 'machine' 'models'\n 'more' 'natural' 'nlp' 'of' 'one' 'performance' 'processing' 'rnns'\n 'simplest' 'subfield' 'such' 'tasks' 'techniques' 'text' 'tf' 'the' 'to'\n 'transformers' 'used' 'vectorization' 'widely' 'word' 'words']\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"print(\" BoW Matrix:\\n\", bow.toarray())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T09:47:57.254760Z","iopub.execute_input":"2025-09-29T09:47:57.255038Z","iopub.status.idle":"2025-09-29T09:47:57.261469Z","shell.execute_reply.started":"2025-09-29T09:47:57.255019Z","shell.execute_reply":"2025-09-29T09:47:57.260243Z"}},"outputs":[{"name":"stdout","text":" BoW Matrix:\n [[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0\n  0 0 0 0 0 0 0 0]\n [0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0\n  0 0 0 1 0 1 0 0]\n [0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0\n  0 0 1 0 0 0 0 0]\n [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 1 0 0 0 1 0 0 0 1 1 0\n  1 0 0 0 1 0 0 1]\n [1 1 1 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n  0 1 0 0 0 0 1 1]]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}